{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problématique sur l'instruction groupby()\n",
    "***\n",
    "\n",
    "Pandas est une librairie très efficace en matière de DS mais elle est très lente.<br>\n",
    "Une 1ère problématique a été relevée pour la lecture des fichiers csv/txt pour les FEC :<br>\n",
    "Le temps de chargement est extrêment lent compte tenu que l'instruction lit cellule par cellule, <br>\n",
    "on a eu recours à la librairie PyArrow.<br>\n",
    "Autre problématique relevée : l'instruction groupby() agit comme une pure boucle 'for' de Python, <br>\n",
    "et là aussi, un FEC d'une taille de 100Mo, l'instruction groupby() s'exécute au bout de 6 minutes environ.<br>\n",
    "Il y a une librairie qui peut résoudre cette lenteur pour certaines instructions de Pandas <br>\n",
    "(Lien : https://www.kdnuggets.com/2019/11/speed-up-pandas-4x.html), mais pas pour GroupBy() qui a <br>\n",
    "été résolue à partir du programme ci-dessous.<br>\n",
    "\n",
    "Éditeur : Laurent REYNAUD</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import pandas as pd\n",
    "import pyarrow.csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin et nom du FEC à charger\n",
    "my_path = 'C:/Users/LRCOM/pythonProjects/lr_dscf1/123456789FEC20171231.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des traitements opérés sur le FEC en matière de DS\n",
    "# accounting_ledger = ds.Treatments(my_path).my_df\n",
    "# balance = ds.Treatments(my_path).balance    \n",
    "# audit = ds.Treatments(my_path).audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Récupération du fichier .csv en DF pyarrow\n",
    "my_df = csv.read_csv(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Conversion de la DF pyarrow sous format pandas\n",
    "my_df = my_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Récupération des champs JournalCode et JournalLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Méthode groupby()\n",
    "# my_df_sum = my_df.groupby(['JournalCode', 'JournalLib'])['EcritureNum'].sum().reset_index()\n",
    "# my_df_sum.drop(columns=['EcritureNum'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autre méthode que groupby() détaillée dans les instructions ci-après\n",
    "df_journal = my_df[['JournalCode', 'JournalLib']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journal['Désignation'] = df_journal['JournalLib'] + '-' + df_journal['JournalCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = df_journal['Désignation'].unique()\n",
    "my_list = my_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_journal = []\n",
    "lib_journal = []\n",
    "for i in my_list:\n",
    "    code_journal.append(i.split('-', 1)[1])\n",
    "    lib_journal.append(i.split('-', 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['29', 'DEUTSCHE BANK'],\n",
       " ['35', 'CIC'],\n",
       " ['60', 'JOURNAL DES ACHATS'],\n",
       " ['70', 'JOURNAL DE VENTES'],\n",
       " ['80', 'OPERATIONS DIVERSES'],\n",
       " ['81', 'OD DE TVA'],\n",
       " ['96', 'CHEQUES A ENCAISSER'],\n",
       " ['97', 'EFFETS A RECEVOIR'],\n",
       " ['AA', 'Ecriture immo.'],\n",
       " ['AB', 'Pièce comptable'],\n",
       " ['AF', 'Ecritures amort.'],\n",
       " ['DA', 'Pièce client'],\n",
       " ['DR', 'Facture client'],\n",
       " ['DV', 'Avoir client avis'],\n",
       " ['FAR', 'FACTURES A RECEVOIR'],\n",
       " ['GV', 'Facture GS'],\n",
       " ['KA', 'Pièce fournisseur'],\n",
       " ['KD', 'Avoir Fournis.'],\n",
       " ['KG', 'Note crédit fourn.'],\n",
       " ['KN', 'Net fournisseurs'],\n",
       " ['KP', 'Gestion de compte'],\n",
       " ['KR', 'Facture fournisseur'],\n",
       " ['OP', 'Pièce comptable'],\n",
       " ['PAIE', 'JOURNAL DE PAIE'],\n",
       " ['PR', 'Modification de prix'],\n",
       " ['RAN', 'Report A Nouveau'],\n",
       " ['RN', 'Facture (net)'],\n",
       " ['RS', 'Facture (net)ext.'],\n",
       " ['RV', 'Reprise de facture'],\n",
       " ['SA', 'Pièce compte général'],\n",
       " ['ST', 'extourne'],\n",
       " ['WA', 'Sortie marchandises'],\n",
       " ['WE', 'Entrée marchandises'],\n",
       " ['WI', \"Pièce d'inventaire\"],\n",
       " ['WL', 'Sortie march./Livr.'],\n",
       " ['ZS', 'check Payment'],\n",
       " ['ZV', 'Compens. paiement']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({'Code': code_journal, 'Désignation': lib_journal}).sort_values(by='Code')\n",
    "list_journal = new_df.to_numpy().tolist()\n",
    "list_journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Récupération d'une classe du PCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 19 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compte</th>\n",
       "      <th>EcritureNum</th>\n",
       "      <th>JournalCode</th>\n",
       "      <th>EcritureDate</th>\n",
       "      <th>Intitule</th>\n",
       "      <th>EcritureLib</th>\n",
       "      <th>PieceRef</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "      <th>EcritureLet</th>\n",
       "      <th>...</th>\n",
       "      <th>PieceDate</th>\n",
       "      <th>ValidDate</th>\n",
       "      <th>Montantdevise</th>\n",
       "      <th>Idevise</th>\n",
       "      <th>DateLet</th>\n",
       "      <th>EcritureDate_time</th>\n",
       "      <th>PieceDate_time</th>\n",
       "      <th>ValidDate_time</th>\n",
       "      <th>DateLet_time</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compte  EcritureNum  JournalCode  EcritureDate  Intitule  EcritureLib  \\\n",
       "0  101300            1            1             1         1            1   \n",
       "1  106110            1            1             1         1            1   \n",
       "2  110000            3            3             3         3            3   \n",
       "3  129000            2            2             2         2            2   \n",
       "\n",
       "   PieceRef  Debit  Credit  EcritureLet  ...  PieceDate  ValidDate  \\\n",
       "0         1      1       1            1  ...          1          1   \n",
       "1         1      1       1            1  ...          1          1   \n",
       "2         3      3       3            3  ...          3          3   \n",
       "3         2      2       2            2  ...          2          2   \n",
       "\n",
       "   Montantdevise  Idevise  DateLet  EcritureDate_time  PieceDate_time  \\\n",
       "0              1        0        1                  1               1   \n",
       "1              1        0        1                  1               1   \n",
       "2              3        0        3                  3               3   \n",
       "3              2        0        2                  2               2   \n",
       "\n",
       "   ValidDate_time  DateLet_time  __index_level_0__  \n",
       "0               1             0                  1  \n",
       "1               1             0                  1  \n",
       "2               3             0                  3  \n",
       "3               2             0                  2  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Méthode groupby()\n",
    "accounts = my_df.loc[my_df['Compte'].astype('str').str.contains('^1')]\n",
    "accounts.groupby('Compte').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['129000', '106110', '110000', '101300'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Autre méthode que groupby() détaillée dans les instructions ci-après\n",
    "accounts = my_df.loc[my_df['Compte'].astype('str').str.contains('^1')]\n",
    "accounts['Compte'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a66343b811b751c2e919a98eaf18e130d7f36e7e5c88e86a0e0812e72df5f60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
